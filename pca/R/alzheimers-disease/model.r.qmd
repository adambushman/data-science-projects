---
title: "PCA & Clustering | Alzheimer's disease data"
description: "Leveraging principal component analysis and clustering as exploratory analysis techniques in Alzheimer's disease attributes."
author: "Adam Bushman"
date: "11/19/2024"
format: 
    html:
        toc: true
        theme: simplex
        smooth-scroll: true
        embed-resources: true
execute:
    warning: false
    error: false
---


# Assignment Questions

## Name

>   What is your name? Include all team members if submitting as a group.

Adam Bushman [u6049169]; no group members.


## Perspective

>   From what perspective ar you conducting the analysis? (Who are you? / Who are you working for?)

I am statistician working with a group of researchers dedicated to better understanding of early Alzheimer's detection. Despite no cure for the disease, early detection and diagnosis is critical for proper treatment to slow and mitigate onset of symptoms.

## Question

>   What is your question?

Our research group has collected data from 333 individuals, some with cognitive impairment and others who are perfectly healthy. These attributes (columns) range from demographics to protein measurements to dementia scores.

Our question is:

>   

## Data set

>   Describe your dataset(s) including URL (if available)

Data sourced from Posit via their 
[{modeldata}](https://modeldata.tidymodels.org/reference/ad_data.html) package, accessed November 14th, 2024. Named *[Alzheimer's disease data](https://modeldata.tidymodels.org/reference/ad_data.html)*, the data were originally sourced from *Kuhn, M., Johnson, K. (2013) Applied Predictive Modeling, Springer*, which derived observations from a clinical study of 333 patients. Citation:

>   Craig-Schapiro R, Kuhn M, Xiong C, Pickering EH, Liu J, Misko TP, et al. (2011) Multiplexed Immunoassay Panel Identifies Novel CSF Biomarkers for Alzheimer's Disease Diagnosis and Prognosis. PLoS ONE 6(4): e18850.


## Variables

>   What are your variables? Include variable type (binary, categorical, numeric). If you have many variables, you can list the most important and summarize the rest (e.g. important variables are... also, 12 other binary, 5 categorical...).

This data set features 131 columns. Two factors and the rest numeric.

One is a natural dependent variable, `Class`, indicating if the patient is symptomatic of cognitive impairment or healthy. Since this exercise is not concerned with predictive modeling, we'll largely treat this variable as an independent. All remaining variables are independent. 

The most important are...

For a complete list of each feature and their data types, navigate to the [feature summary](#feature-summary).


## Model resonability

>   How are your variables suitable for your analysis method?

...


## Conclusions

>   What are your conclusions (include references to one or two CLEARLY INDICATED AND IMPORTANT graphs or tables in your output)?

...

## Assumptions

>   What are your assumptions and limitations? Did you include any robustness checks?

...


# Assignment Workflow
 
## Analysis Prep

### Loading packages

```{r}
library('tidyverse')        # Wrapper for many convenient libraries
library('modeldata')        # Contains data for the assignment
library('skimr')            # Quickly summarise data
library('gt')               # Render "great tables"

library('dataPreparation')  # Utilities for PCA prep
```

### Loading the data

We'll start off by referencing the "Alzeimer's Data" for the assignment from the `{modeldata}` package.

```{r}
ad_raw <- modeldata::ad_data        # Data for the assignment
```

With it loaded into the session, let's get a sense for what we're working with.

### Data set inspection

Normally, I like to get acquainted a data set. That means understanding what each column seeks to describe, confirming the granularity of the rows, and getting my arms around structure, completeness, distribution, etc. We'll certainly do some of that, but this data set has over 130 columns.

Posit, the company behind `{modeldata}`, included the following summary of features classes captured in the dataset:

>   *   Demographic characteristics such as age and gender
*   Apolipoprotein E genotype
*   Protein measurements of Abeta, Tau, and a phosphorylated version of Tau (called pTau)
*   Protein measurements of 124 exploratory biomarkers, and
*   Clinical dementia scores


Using the `{skimr}` package, we can get a comprehensive summary of the data.
:::{#feature-summary}
```{r}
skim(ad_raw)
```
:::
<br>

Initial observations include:

*   333 rows represent the number of patients in the clinical study
*   We have two factor variables: `Genotype` and `Class`
    *   In theory, the `male` variable could be cast as a factor
*   We then have over 100 variables that are all numeric and all complete. So far, we haven't a clear understanding of the interplay and importance of these data points


## Exploratory Data Analysis

Our goal is to learn about the interplay and imporance of the various features in this data set. We'll use and combine Principal Component and Clustering analysis techniques. 

We'll follow a typical implementation, where we cluster the raw data, perform PCA, and then implement the same clustering analysis on the PCA output. We'll then determine where the most meaningful interpretation is derived.

### Clustering (phase 1)


### Principal Component Analysis

#### Preprocessing

For PCA to work properly, we need to standardize the values (i.e. mean of zero, standard deviation of 1). This will prevent any unwarranted weighting of certain variables to others.

```{r}
ad_numeric <- ad_raw |> select(where(is.numeric))
```

```{r}
scale_obj <- build_scales(data_set = ad_numeric)
ad_scaled <- fast_scale(data_set = ad_numeric, scales = scale_obj, verbose = TRUE)
```

#### Calculation

```{r}
ad_cov <- cov(ad_scaled)
ad_eig <- eigen(ad_cov)

ad_eig_val <- ad_eig$values
ad_eig_vec <- ad_eig$vectors
```

```{r}
var_expl <- round(ad_eig_val / sum(ad_eig_val), 3)
cum_var_expl <- cumsum(var_expl)
```

```{r}
pca_results <- data.frame(
    var = cum_var_expl, 
    idx = 1:length(cum_var_expl)
)

thresh <- c(0.5, 0.75, 0.9, 0.95)
idx <- sapply(thresh, function(t) which.min(abs(cum_var_expl - t)))

pca_thresh <- data.frame(thresh, idx)
```

#### Results Plots

```{r}
ggplot() +
    geom_area(aes(x = idx, y = var), pca_results, fill = "#E2E6E6") +
    geom_vline(aes(xintercept = idx), pca_thresh, color = "#BE0000") +
    geom_label(
        aes(
            x = idx, y = thresh, 
            label = stringr::str_wrap(
                paste("First", idx, "of", length(cum_var_expl), "principal components explain", thresh * 100, "% of overall variance"), 20
            )
        ), 
        pca_thresh, 
        color = "#BE0000"
    ) +
    scale_y_continuous(expand = expansion(mult = c(0,.05))) +
    labs(
        title = "Cumulative variance explained by first X principal component(s)", 
        subtitle = paste0("A summary of PCA results compared to original column dimensions (", length(cum_var_expl), ")"), 
        x = "Principal Component Index", 
        y = "% of Variance Explained"
    ) +
    theme_minimal()
```

We could also generate a plot comparing the Alzheimer `class` against the first two principal components and the final two.

```{r}
pca_scores <- ad_scaled * ad_eig_vec
```

```{r}
pca_groups <- tibble(
    class = ad_raw$Class, 
    pc_1 = unlist(pca_scores[,1], use.names = FALSE), 
    pc_2 = unlist(pca_scores[,2], use.names = FALSE), 
    pc_114 = unlist(pca_scores[,114], use.names = FALSE), 
    pc_115 = unlist(pca_scores[,115], use.names = FALSE)
)
```

```{r}
ggplot(pca_groups) +
    geom_point(
        aes(pc_1, pc_2, color = class)
    ) +
    labs(
        title = "Comparison of principal components by `Class`", 
        subtitle = "Among 1st and 2nd principal components", 
        x = paste0("Dimension 1 (", var_expl[1] * 100, "%)"), 
        y = paste0("Dimension 2 (", var_expl[2] * 100, "%)")
    ) +
    theme_minimal()
```

```{r}
ggplot(pca_groups) +
    geom_point(
        aes(pc_114, pc_115, color = class)
    ) +
    labs(
        title = "Comparison of principal components by `Class`", 
        subtitle = "Among 114th and 115th principal components", 
        x = paste0("Dimension 114 (", var_expl[114] * 100, "%)"), 
        y = paste0("Dimension 115 (", var_expl[115] * 100, "%)")
    ) +
    theme_minimal()
```


### Clustering (phase 2)


## Results

