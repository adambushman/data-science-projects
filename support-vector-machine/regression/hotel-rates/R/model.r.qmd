---
title: "Support Vector Machine | Hotel Rates"
description: "Leveraging support vector machines in R to predict hotel rates"
author: "Adam Bushman"
date: "10/22/2024"
format: 
    html:
        toc: true
        theme: simplex
        smooth-scroll: true
        embed-resources: true
execute:
    warning: false
    error: false
---


# Assignment Questions

## Name
>   What is your name? Include all team members if submitting as a group.

Adam Bushman [u6049169]; no group members.


## Perspective
>   From what perspective ar you conducting the analysis? (Who are you? / Who are you working for?)

I am a data consultant for a hotel chain. They are interested in standardizing pricing strategies and have recruited me to help. They are hoping for a predictive model for nightly room rates. They want to test drive the approach using a single hotel they suspect has had some inconsistent pricing strategies.


## Question
>   What is your question?

Can a predictive model be generated on historical nightly room rates such that 1) underlying patterns are accounted for and 2) unwanted variance is "smoothed" for better consistency across locations within the chain.

The goal would be to settle on a model that fairly explains the variance but isn't sensitive enough to the suspected anomalies of single hotel location.


## Data set
>   Describe your dataset(s) including URL (if available)

The data set is sourced from Posit via their [{modeldata}](https://modeldata.tidymodels.org/reference/hotel_rates.html) package. It turns out the original source was a publication in *Antonio, de Almeida, and Nunes (2019)* and represents historical rates a single hotel (the "Resort Hotel") in Lisbon, Portugal.


## Predictor(s) and target(s)
>   What is (are) your independent variable(s) and dependent variable(s)? Include variable type (binary, categorical, numeric).

Little was described about the data here in Posit's reference. However, a comprehensive [dictionary](https://www.sciencedirect.com/science/article/pii/S2352340918315191#bib5) was found that wholistically described the variables.

The data set features 28 columns and just over 15.4K rows. There are 9 features of type `factor`, 18 of type `numeric`, and 1 of type `date`. A comprehensive table of variable names, data types, and descriptions can be found [here](#data-dictionary).

The dependent variable (target) aligning with the use case is `avg_price_per_room`. The independent variables included all but `arrival_date` (much of the seasonality seen in dates is captured via other features, such as `near_christmas` and `stays_in_weekend_nights`).


## Model resonability
>   How are your variables suitable for your analysis method?

The variables chosen are suitable for the analysis method of a Support Vector Machine thanks to the following:

*   Many features; while the data set only technically includes 28 columns, there are some categorical fields that contain a high number of unique values. While note explicitly performed 
*   Generalization; SVM's do a good job at avoiding overfitting provided the data is pre-processed properly

The model may not be the ultimate best choice given other considerations:

*   SVM for classification; generally, Support Vector Machines are used for classification problems but can be deployed in regression scenarios, though less popular
    *   While potentially unorthodox, I was interested in the viability of Support Vector Regression
*   Many records; using kernel tricks will be computationally intensive with the entire data set


## Conclusions
>   What are your conclusions (include references to one or two CLEARLY INDICATED AND IMPORTANT graphs or tables in your output)?

The SVM regression model predicted average nightly hotel rates/prices balancing results of $RMSE$ and $R^2$ in cross-validation tuning for `cost` and `sigma` on the training data. 

Based on the tuning results [visualized in this graph](#tuning-results), a custom model was fitted to the training data with custom `cost` and `sigma` values.

The resulting model is adequate, with performance similar to what was found in cross-validated examples (see resulting $RMSE$ and $R^2$ figures [here](#final-results)).

It is anticipated the hotel chain will be sufficiently encouraged with this first step and, upon review of the below assumptions, is prepared to invest additional time to improving the model.


## Assumptions
>   What are your assumptions and limitations? Did you include any robustness checks?

#### SVM regression

I wanted to explore the viability of SVM's in a regression setting. While traditionally applied to classification problems, they can be applied to regression situations and I wanted to explore that. 

I have a sense now that it can be a fair alternative to the OLS family of regression should the data set fail to meet its rigorous assumptions. However, it does have a cost, namely 

1.  Computation (the models took a long time to run and I had to reduce the data set dimensions)
2.  Iterpretability (there really is no way to peel back the curtain and evaluate individual relationships)
3.  Performance (the results left some to be desired)
    *   Model evaluation via $RMSE$ and $R^2$


#### Chosen values for cross-valdiated hyperparameters

I chose to use the following values for SVM hyperparameters

*   sigma: 0.01, 0.10, 0.50
*   cost: 0.05, 1.00, 3.00

In one sense, these are arbitrary; I had no rules of thumb, per se. However, I try to cover a reasonably wide range of possible values. The idea is to explore the performance of hyperparameter values across differing thresholds and methodically discover good ranges.


#### Not transforming target variable

Due to time and complexity, I opted to not center, scale, and transform the target variable. This certainly affected the quality of the predictions. With more time this is a critical next step to boosting performance.


# Assignment Workflow
 
## Analysis Prep

### Loading packages

```{r}
library('tidyverse')        # Wrapper for many convenient libraries
library('modeldata')        # Contains data for the assignment
library('skimr')            # Quickly summarise data
library('gt')               # Render "great tables"

library('e1071')           # Loading library for SVM
library('rsample')
library('caret')
```

### Loading the data

We'll start off by referencing the "Hotel Rates" data for the assignment that we're sourcing from the `{modeldata}` package.

```{r}
hotel_raw <- modeldata::hotel_rates        # Data for the assignment
```

With it loaded into the session, let's get a sense for what we're working with.

### Data set inspection

Right away, I like to get acquainted with the data set. That means understanding what each column seeks to describe, confirming the granularity of the rows, and getting my arms around structure, completeness, distribution, etc.

Posit, the company behind `{modeldata}`, did not include a data dictionary; however, the variables are sufficiently self-explanatory. Below is a derived data dictionary:

```{r}
#| include: false

dict_list <- list(
    list(variable = "avg_price_per_room", datatype = "<double>", description = "Sum of all lodging transactions divided by total number of staying nights"), 
    list(variable = "lead_time", datatype = "<double>", description = "Number of days that elapsed between the entering date of the booking into the PMS and the arrival date"), 
    list(variable = "stays_in_weekend_nights", datatype = "<double>", description = "Number of weekend nights (Saturday or Sunday) the guest stayed or booked to stay at the hotel"), 
    list(variable = "stays_in_week_nights", datatype = "<double>", description = "Number of week nights (Monday to Friday) the guest stayed or booked to stay at the hotel"), 
    list(variable = "adults", datatype = "<double>", description = "Number of adults"), 
    list(variable = "children", datatype = "<double>", description = "Number of children"), 
    list(variable = "babies", datatype = "<double>", description = "Number of babies"), 
    list(variable = "meal", datatype = "<factor>", description = "Type of meal booked"), 
    list(variable = "country", datatype = "<factor>", description = "Country of origin"), 
    list(variable = "market_segment", datatype = "<factor>", description = "Market segment designation: travel agents (TA), tour operators (TO), etc."), 
    list(variable = "distribution_channel", datatype = "<factor>", description = "Booking distribution channel: travel agents (TA), tour operators (TO), etc."), 
    list(variable = "is_repeated_guest", datatype = "<double>", description = "Value indicating if the booking name was from a repeated guest (1) or not (0)"), 
    list(variable = "previous_cancellations", datatype = "<double>", description = "Number of previous bookings that were cancelled by the customer prior to the current booking"), 
    list(variable = "previous_bookings_not_canceled", datatype = "<double>", description = "Number of previous bookings not cancelled by the customer prior to the current booking"), 
    list(variable = "reserved_room_type", datatype = "<factor>", description = "Code of room type reserved"), 
    list(variable = "assigned_room_type", datatype = "<factor>", description = "Code for the type of room assigned to the booking. Sometimes the assigned room type differs from the reserved room type"), 
    list(variable = "booking_changes", datatype = "<double>", description = "Number of changes/amendments made to the booking from the moment the booking was entered on the PMS until the moment of check-in or cancellation"), 
    list(variable = "agent", datatype = "<factor>", description = "ID of the travel agency that made the booking"), 
    list(variable = "company", datatype = "<factor>", description = "	ID of the company/entity that made the booking or responsible for paying the booking"), 
    list(variable = "days_in_waiting_list", datatype = "<double>", description = "Number of days the booking was in the waiting list before it was confirmed to the customer"), 
    list(variable = "customer_type", datatype = "<factor>", description = "Type of booking, assuming one of four categories: contract, group, transient, transient-party"), 
    list(variable = "required_car_parking_spaces", datatype = "<double>", description = "Number of car parking spaces required by the customer"), 
    list(variable = "total_of_special_requests", datatype = "<double>", description = "Number of special requests made by the customer (e.g. twin bed or high floor)"), 
    list(variable = "arrival_date", datatype = "<date>", description = ""), 
    list(variable = "arrival_date_num", datatype = "<double>", description = "Date of arrival for hotel stay"), 
    list(variable = "near_christmas", datatype = "<double>", description = "Flag for hotel stays near christmas"), 
    list(variable = "near_new_years", datatype = "<double>", description = "Flag for hotel stays near new years"), 
    list(variable = "historical_adr", datatype = "<double>", description = "Historical average daily rate/price per room")
)

hotel_dict <- do.call(rbind, lapply(dict_list, as.data.frame))
```

::: {#data-dictionary}
```{r}
#| html-table-processing: none

gt(hotel_dict) %>%                                   # Create a "great tables" (gt) object
    cols_label(                                         # Rename some columns
        variable = "Variable Name", 
        datatype = "Data Type", 
        description = "Variable Description"
    ) %>%
    tab_options(
        column_labels.background.color = "#d9230f",     # Apply red header background
        column_labels.font.weight = "bold",             # Bold headers
        row.striping.background = '#FFFFFF'             # Remove row striping
    )

```
:::

Using the `{skimr}` package, we can get a comprehensive summary of the data.

```{r}
skim(hotel_raw)
```
<br>

Initial observations include:

*   With over 15K rows, we may be on the brink of *too much* data suitable for a support vector machine model; we may want to randomly sample for this set
*   We have no missing values; this means we won't have to eliminate records, features, or determine the best way to impute values
*   We do have some skewed distributions, most long, right tails; we'd likely benefit from some logarithmic transformations and natural scaling
*   An SVM model should handle many features well; we have some factor data types with many unique values
    *   country, agent, company


## Simple Exploratory Data Analysis



## Preprocessing

### Data cleaning / Feature Engineering

As mentioned, we'd be wise to transform and scale numeric variables that are highly skewed to the right. We'll do this for all but the target variable.

We can do this fairly easy with the following code:

```{r}
hotel_clean <- 
    hotel_raw |>
    mutate(arrival_date_char = factor(as.character(arrival_date_num))) |>
    mutate(across(
        where(is.numeric) & !c(avg_price_per_room), 
        ~as.numeric(scale(log(. + 0.01 * max(.))))
    )) |>
    select(-arrival_date_num)
```

```{r}
glimpse(hotel_clean)
```

Now we have columns that are 1) logarithmically transformed to approximate the normal distribution and 2) scaled for normality (mean = 0, stdev = 1).

We don't have any constants, doubles, or bijections in the data, so no need to account for those.


## Model resources

### Splitting for training/testing sets

As is customary, we must split our data into training and testing sets. We'll put aside the testing set and work with training until we're comfortable with our model definition. The `{rsample}` package has a lot of helpful functions for this workflow. In just a couple lines we get training and testing sets.

```{r}
set.seed(819)                                                               # Set reproducible seed
hotel_sampl <- sample_n(hotel_clean, ceiling(nrow(hotel_clean) * 0.25))     # Take a quarter of the data randomly
split_obj <- initial_split(hotel_sampl, prop = 0.75)                        # Split object

hotel_train <- training(split_obj)                                          # Split for training
hotel_test <- testing(split_obj)                                            # Split for testing
```

::: {.callout-note}
To expedite the computational process of cross-validating an SVM model, the data was trimmed by 75% via random sampling prior to training/testing splits.
:::


## Training and tuning

### Cross validation tuning

What we want to do is setup some cross validation for the hyperparameters needed by SVM, specifically *sigma* and *cost*. We can do that with `{caret}` and its `trainControl()` function:

```{r}
fit_summary <- function(data, lev = NULL, model = NULL) {
  RMSE <- sqrt(mean((data$obs - data$pred)^2))
  R2 <- cor(data$obs, data$pred)^2
  
  out <- c(rmse = RMSE, rsq = R2)
  return(out)
}

fit_control <- trainControl(
    method = "repeatedcv", 
    number = 3, 
    repeats = 3, 
    summaryFunction = fit_summary
)

fit_grid <- expand.grid(
    sigma = c(0.01, 0.1, 0.5), 
    C = c(0.05, 1, 3)
)
```

Next, we define an SVM model using these tuning and cross validation settings.

```{r}
svm_fit <- train(
    avg_price_per_room ~ . -arrival_date, 
    data = hotel_train, 
    method = "svmRadial", 
    trControl = fit_control, 
    metric = "Rsquared", 
    preProcess = NULL, 
    tuneGrid = fit_grid
)
```


```{r}
svm_fit
```

The fitted model description gives us some good info:

*   We see the values for sigma and cost (C) that we had defined in our tuning grid
*   We see metric values we defined in the train function

We can use this information to make judgements about the best hyper parameters.


### Evaluating tuning

Let's use the produced information to generate a plot. We want to see what happens to $RMSE$ and $R^2$ given the changes made to sigma and C.

First, let's pivot the data to make plotting easier:

```{r}
results_df <- svm_fit$results |>
    select(-c(rmseSD, rsqSD)) |>
    pivot_longer(
        cols = c("rmse", "rsq"),
        names_to = "metric",
        values_to = "metric_val"
    ) |>
    pivot_longer(
        cols = c("sigma", "C"),
        names_to = "hyperparameter",
        values_to = "hyperparameter_val"
    )

results_df
```

Now let's generate a faceted plot:

:::{#tuning-results}
```{r}
ggplot(
    results_df, 
    aes(hyperparameter_val, metric_val)
) +
    geom_line() +
    geom_point() +
    facet_grid(metric~hyperparameter, scales = "free") +
    theme_minimal() +                                                           # Theme styling
    theme(
        panel.background = element_rect(color = "#707271"), 
        axis.title.x = element_blank(), 
        axis.title.y = element_blank(), 
        panel.grid.major.x = element_blank(), 
        strip.background = element_rect(fill = "#BE0000"), 
        strip.text = element_text(color = "white", face = "bold")
    )
```
:::

We can look at this plot top to bottom, left to right.

1.  Hyperparameter "C"
    *   $RMSE$ oscilates high to low as as cost goes up
    *   $R^2$ also jumps up and down as cost goes up
    *   No clear indication of a threshold being crossed with cost
2.  Sigma
    *   $RMSE$ starts low with sigma being low and then spikes (remember, we want this error low)
    *   $R^2$ does the opposite, starting high and the tanking (remember, we want this value high)
    *   Clearly, we want Sigma to be low

We'll proceed to use a custom model that balances both of these well: $C = 0.05$ and $sigma = 0.01$.


## Final model

### Define final model

We'll create a custom SVM model using the hyperparameters evaluated above.

```{r}
svm_custom <- svm(
    avg_price_per_room ~ . -arrival_date, 
    data = hotel_train, 
    cost = 0.05, 
    sigma = 0.01
)
```


### Predict on testing

Let's proceed to predict values using the tuned model from above but on the testing data set.

```{r}
svm_pred <- predict(svm_custom, newdata = hotel_test)
```

Let's combine these values back with our original prices and print 10 random values:

```{r}
model_results <- 
    hotel_test |>
    select(actual_rate = avg_price_per_room) |>
    mutate(pred_rate = svm_pred)

model_results |>
    sample_n(10)
```


## Results

We can calculate the final $RMSE$ and $R^2$ on the predictions:

:::{#final-results}
```{r}
list(
    RMSE = sqrt(mean((model_results$actual_rate - model_results$pred_rate)^2)), 
    R2 = cor(model_results$actual_rate, model_results$pred_rate)^2
)
```
:::