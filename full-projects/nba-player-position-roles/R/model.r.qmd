---
title: "Position/role classification of incoming NBA prospects"
description: "Leveraging multiple machine learning methods in R to cluster for player positions/roles and predict the same for incoming NBA prospects."
author: "Adam Bushman"
date: "12/12/2024"
format: 
    html:
        toc: true
        theme: simplex
        smooth-scroll: true
        embed-resources: true
execute:
    warning: false
    error: false
---


# Assignment Workflow

## Organizational Theory

## Data Prep

### Load Libraries & Data Set

```{r}
library("tidyverse")
library("tidymodels")
library("tidyclust")
library("dataPreparation")

library("kernlab") # Weighted kernal k-means
```

```{r}
#| eval: false
setwd("full-projects/nba-player-position-roles/R")
```

Import the data

```{r}
nba_stats <- read.csv("../nba-player-data.csv")
```

```{r}
glimpse(nba_stats)
```

```{r}
# Check for missing or empty values
na_summary <- sapply(nba_stats, function(col) {
    sum(is.na(col) | is.null(col) | col == "", na.rm = TRUE)
})

any(na_summary > 0)
```


### Scale Variables

```{r}
nba_numeric <- nba_stats |> select(
    where(is.numeric) &
        -c(profile_height_in, profile_weight_lbs)
)

nba_ids <- nba_stats |> select(
    where(is.character) |
        c(profile_games_played, profile_minutes, profile_height_in, profile_weight_lbs)
)
```

```{r}
# Check for non-finite values
nonf_summary <- sapply(nba_numeric, function(col) {
    sum(!is.finite(col), na.rm = TRUE)
})

any(nonf_summary > 0)
```

Create volume adjusted measures based on minutes (i.e. points per "36 minutes", an industry standard).

```{r}
nba_adjusted <- nba_numeric |>
    mutate(across(
        where(is.integer) & -c(profile_games_played, profile_minutes),
        ~ . * 36.0 / profile_minutes
    )) |>
    select(-c(profile_games_played, profile_minutes))
```

We also remove the total volume measures as we want to prevent clusters that are similar just based on how much they play.

Scale the numeric variables:

```{r}
nba_scaled <- scale(nba_adjusted)
```

### Principal Component Analysis

Using the scaled variables, let's perform PCA. We'll try to cluster with and without PCA. We'll have both data set versions at our disposal for clustering.

```{r}
library("FactoMineR")
```

```{r}
nba_pca <- princomp(nba_scaled)
```

```{r}
summary(nba_pca)
```

We have 195 numeric, source variables so 199 principal components. The first 15 components explain 75% of variance, the first 40 explain 90% of the variance and the first 57 principal components explain 95%. That means just over 1/4 of our original number of features explain nearly all of the total variance. 

PCA did a good job at 1) reducing dimensionality and 2) eliminating any colinearity of features. 

Let's save our results:

```{r}
nba_pca_data <- as.data.frame(nba_pca$scores)
```

Let's visualize some of these principal components:

```{r}
ggplot(
    nba_pca_data,
    aes(Comp.1, Comp.2)
) +
    geom_point()
```


## Clustering

Let's try to cluster these observations.

Historically, basketball has used 5 positions. In modern times, this has been reduced to approximately 3. Let's use 3 as our minimum and 12 as our maximum. Let's try a few different clustering techniques.

```{r}
clustering_grid <- data.frame(
    clusters = 3:20
)
```

Against each of these, we can run different clustering algorithms and produce measures for the "within sum of squares". This will help us determine the proper number of clusters derived from the data.


### Partition Clustering

Let's setup a function to run a kmeans cluster for every number of cluster in the above grid and generate the respective performance metric:

```{r}
cluster_kmeans <- function(k, data) {
    fit <- kmeans(data, k)
    vals <- glance(fit)
    return(vals$tot.withinss)
}
```   


### Hierarchical Clustering

Let's do the same thing but for an hclust algorithm:

```{r}
cluster_hclust <- function(k, data) {
    # Run the algorithm
    model <- hier_clust(num_clusters = k, linkage_method = "complete")
    fit <- model |> fit(~., data = as.data.frame(data))

    wss <- fit |>
        sse_within() |>
        select(wss) |>
        unlist() |>
        sum()
    return(wss)
}
```

Let's now generate our clusters!

### Cluster Results

Let's map over the number of clusters and execute the respective algorithm.

```{r}
clustering_grid_01 <-
    clustering_grid |>
    mutate(
        kmeans = map(clusters, ~ cluster_kmeans(.x, nba_scaled)),
        hclust = map(clusters, ~ cluster_hclust(.x, nba_scaled))
    )
```

We can now plot these and find the "elbow", or the point of diminishing returns from an increasing the number of clusters.

```{r}
clustering_grid_01 |>
    pivot_longer(cols = -clusters) |>
    unnest(value) |>
    ggplot(aes(factor(clusters), as.numeric(value))) +
    geom_line(aes(color = name), group = 1) +
    facet_wrap(~name, ncol = 1, scales = "free")
```

`hclust` gives the impression that around 10 is the right number of clusters, though the elbow is difficult to identify. `kmeans` suggests 9 or 10.

Let's see if we get different results using just the first 53 principal components. 

```{r}
clustering_grid_02 <-
    clustering_grid |>
    mutate(
        kmeans = map(clusters, ~ cluster_kmeans(.x, nba_pca_data[, 1:57])),
        hclust = map(clusters, ~ cluster_hclust(.x, nba_pca_data[, 1:57]))
    )
```

```{r}
clustering_grid_02 |>
    pivot_longer(cols = -clusters) |>
    unnest(value) |>
    ggplot(aes(factor(clusters), as.numeric(value))) +
    geom_line(aes(color = name), group = 1) +
    facet_wrap(~name, ncol = 1, scales = "free")
```

The same algorithms with the first 57 principal components indicate somewhere around 9 to 10. Let's proceed with the PCA results and assume clusters of `10`. I also think the smoothing of `kmeans` is a little nicer so let's default to that algorithm.

```{r}
set.seed(2015)
fit <- kmeans(nba_pca_data[, 1:57], 10)

nba_ids$cluster <- factor(fit$cluster)
nba_adjusted_full <- nba_adjusted |> mutate(cluster = factor(fit$cluster))
nba_scaled_full <- as.data.frame(nba_scaled) |> mutate(cluster = factor(fit$cluster))

nba_ids |>
    count(cluster) |>
    mutate(prop = n / sum(n))
```

The initial results seem fairly reasonable. Understandably, some clusters (or as we would interpret, "positions"/"roles"/"styles") have more players than others given the nature of the game.

Let's evaluate some specific players and get a sense for the results.

### Cluster Evaluation

The first example deals with 4 players typically thought of as "centers". Their physical profiles are somewhat similar but there are significant differences in style and role. We should probably see three different cluster assignments.

```{r}
nba_ids |> filter(
    profile_name %in% c(
        "Victor Wembanyama",
        "Nikola Jokic",
        "Clint Capela",
        "Rudy Gobert"
    )
)
```

We see Capela and Gobert with the same cluster assignment, making sense, but Jokic and Wembanyama are also assigned to the same. Given their offensive game, this could make sense, as most of their differentiators are on the defensive end.

Let's try another. These three all have similar physical profiles, roles, and play styles. Let's see how they are clustered.

```{r}
nba_ids |> filter(
    profile_name %in% c(
        "Jimmy Butler",
        "Jayson Tatum",
        "Jaylen Brown"
    )
)
```

We see they all fall into the same cluster! This gives some assurance that the clustering is capturing some of the inherent patterns.

What about all players who've historically been labeled "point guards". Each of these play so differently we should see completely different cluster assignments.

```{r}
nba_ids |> filter(
    profile_name %in% c(
        "Collin Sexton",
        "Bruce Brown",
        "Stephen Curry",
        "Jose Alvarado"
    )
)
```

All different except for Curry and Sexton. We'll have to dig into the cluster more closely to learn about this. So far its tracking pretty close to what a contextual lens might suggest.

Let's look at at some of the most dissimilar players from a physical profile that have the same cluster.

```{r}
getMinMax <- function(data, cluster = 1) {
    data_f <- data[data$cluster == cluster, ]
    data_f$val <- (scale(data_f$profile_height_in) + scale(data_f$profile_weight_lbs)) / 2
    data_f <- data_f |> arrange(desc(val))

    return(c(
        data_f$profile_name[nrow(data_f)],
        data_f$profile_name[1]
    ))
}
```

```{r}
for (c in sort(unique(nba_ids$cluster))) {
    players <- getMinMax(nba_ids, c)
    print(paste(
        c, "- Min:", players[1],
        "| Max:", players[2]
    ))
}
```

Generally speaking, these make a lot of sense. The next step would be to analyze each cluster and come up with unique labels for them that describe the new position/role/style.


### Cluster Naming

Clusters are labeled arbitrarily. There's nothing intuitive by labels `1`, `2`, etc. We need to give these clusters meaning by assigning `1` a descriptive label.

We'll do that two ways:

1.  We'll create a penalized logistic regression model for each individual cluster and select the highest absolute value of the coefficients. In this way, we can understand some of the predictors that define the cluster.

2.  We'll leverage AI to use what it knows about the players in each cluster to give label suggestions.

We'll pool these perspectives together to generate our own label. We'll save the label in the following table:

```{r}
cluster_labels <- tibble(
    cluster = factor(1:10),
    label = as.character(NA), 
    abbrev = as.character(NA), 
)
```


#### Guidelines

We want to shy away from traditional language: "guard", "forward", "center". Even labels like "backcourt", "frontcourt" can pigeonhole a group of players in unhelpful ways, potentially. Additionally, modern terms like "wing" and "big" we may want to shy away from.

This puts more emphasis on style of play and role than physical profile or position.


#### Top Features Model

Here's the function that will ingest our dataset, classifify against a binary target (`1` = cluster of interest, `0` = all other clusters).

We'll perform cross validation, take the best model, fit on the entire data set, and take the top coefficients.

```{r}
get_elasnet_top_features <- function(data) {
    # Configure recipe
    mod_rec <- recipe(target ~ ., data)

    # Setup cross-validation folds
    mod_cv <- rsample::vfold_cv(data, v = 5)

    # Configure tuning grid
    mod_tune_grid <- grid_regular(
        penalty(),
        mixture(),
        levels = 4
    )

    # Setup model definition
    mod_def <- logistic_reg(
        mixture = tune(),
        penalty = tune()
    ) |>
        set_engine("glmnet")

    # Configure workflow
    mod_wflw <-
        workflow() |>
        add_model(mod_def) |>
        add_recipe(mod_rec)

    # Define parallelization
    cores_target <- ceiling(parallel::detectCores() * 0.75)
    doParallel::registerDoParallel(cores = cores_target)

    # Run cross-validated tuning
    set.seed(814)
    mod_tune <-
        mod_wflw |>
        tune_grid(
            resamples = mod_cv,
            grid = mod_tune_grid,
            metrics = metric_set(roc_auc)
        )

    # Select & fit best model
    best_mod <- mod_tune |> select_best(metric = "roc_auc")
    final_wflw <- mod_wflw |> finalize_workflow(best_mod)
    final_fit <- fit(final_wflw, data = data)

    # Capture the top predictors by absolute value of coefficient
    tidy(final_fit) |>
        arrange(desc(abs(estimate))) |>
        slice_head(n = 10) |>
        select(-penalty) |>
        print()
}
```

We'll call this for each cluster.


#### Aritificial Intelligence

We're going to let AI suggest some labels. All it will see is 1) our prompt and 2) the player names pertaining to the cluster. This will lead to a less biased approach

This is the prompt we'll use (along with the list of names) against OpenAI's ChatGPT 4o model:

>   Below are a list of recent NBA player names. Assume these players belong in a collective group based on their play style and role. Generate 5 unique suggestions for a group label that is short and sweet but descriptive of the group. Restrict evaluation to style and role; avoid analysis rooted in reputation, playing time, etc.


#### Cluster #1

Player names:

```{r}
nba_ids[nba_ids$cluster == "1", ]$profile_name
```

Let's pull the top features explaining this cluster assignment:

```{r}
target_cluster_df <- nba_scaled_full |>
    mutate(target = factor(ifelse(cluster == "1", 1, 0))) |>
    select(-cluster)

get_elasnet_top_features(target_cluster_df)
```

These top features are interesting. There's clear evidence of a) athleticism and skill in the open court, b) some tendency toward mistakes, and 3) overall sub-impact.  

ChatGPT generated the following label suggestions:

*   Playmaking Hustlers
*   Versatile Initiators
*   Dynamic Facilitators
*   Crafty Drivers
*   Hybrid Creators

I'm somewhat drawn to words like "initiator" and "hustler". I don't see any evidence of "facilitator" or "creator". There's a good mix of physical profile and style. Let's go with "Versatile Anchor".

```{r}
# Save cluster label
cluster_labels[cluster_labels$cluster == "1", 2] <- "Versatile Anchor"
cluster_labels[cluster_labels$cluster == "1", 3] <- "VA"
```

---

#### Cluster #2

Player names:

```{r}
nba_ids[nba_ids$cluster == "2", ]$profile_name
```

Let's pull the top features explaining this cluster assignment:

```{r}
target_cluster_df <- nba_scaled_full |>
    mutate(target = factor(ifelse(cluster == "2", 1, 0))) |>
    select(-cluster)

get_elasnet_top_features(target_cluster_df)
```

What first catches me eye with these features are `second_change_at_rim_frequency` and `at_rim_accuracy`. These are players oriented near the basket. Next what catches my eye are some of the `second_change_3` variations but that are negative. As in lower frequency on second chance opportunities but not necessarily lower on overall 3s.

ChatGPT generated the following label suggestions:

*   Versatile Wings
*   Dynamic Bigs
*   Stretch Forwards
*   Two-Way Frontcourt
*   Hybrid Playmakers

In comparing these options to the player list set, I'm drawn to the "Hybrid Playmakers" label. It's not very descriptive. We have again, a good mix of physical profile and style. Therefore, let's settle on "Versatile Finisher".

```{r}
# Save cluster label
cluster_labels[cluster_labels$cluster == "2", 2] <- "Versatile Finisher"
cluster_labels[cluster_labels$cluster == "2", 3] <- "VF"
```

---

#### Cluster #3

Player names:

```{r}
nba_ids[nba_ids$cluster == "3", ]$profile_name
```

Let's pull the top features explaining this cluster assignment:

```{r}
target_cluster_df <- nba_scaled_full |>
    mutate(target = factor(ifelse(cluster == "3", 1, 0))) |>
    select(-cluster)

get_elasnet_top_features(target_cluster_df)
```

What catches my eye are lower on assist features than other groups but higher rebounders and some hustle stuff here. 

ChatGPT generated the following label suggestions:

*   Scoring Wings
*   Perimeter Playmakers
*   Versatile Shooters
*   Dynamic Swingmen
*   Offensive Engines

I see all of these words in this group to some extent. The combo that most seems interesting is probably "versatile" and "engine", so we'll go with "Versatile Engine".

```{r}
# Save cluster label
cluster_labels[cluster_labels$cluster == "3", 2] <- "Versatile Engine"
cluster_labels[cluster_labels$cluster == "3", 3] <- "VE"
```

---

#### Cluster #4

Player names:

```{r}
nba_ids[nba_ids$cluster == "4", ]$profile_name
```

Let's pull the top features explaining this cluster assignment:

```{r}
target_cluster_df <- nba_scaled_full |>
    mutate(target = factor(ifelse(cluster == "4", 1, 0))) |>
    select(-cluster)

get_elasnet_top_features(target_cluster_df)
```

This group is pretty clear. Scoring, creating, playmaking.

ChatGPT generated the following label suggestions:

*   Elite Creators
*   Dynamic Scorers
*   Playmaking Stars
*   Offensive Leaders
*   All-Around Playmakers

To borrow a word from a previous cluster, I like the word "engine". These are the players that engage the team's "drivetrain", so to speak. Let's go with "Perimeter Engine".

```{r}
# Save cluster label
cluster_labels[cluster_labels$cluster == "4", 2] <- "Perimeter Engine"
cluster_labels[cluster_labels$cluster == "4", 3] <- "PE"
```

---

#### Cluster #5

Player names:

```{r}
nba_ids[nba_ids$cluster == "5", ]$profile_name
```

Let's pull the top features explaining this cluster assignment:

```{r}
target_cluster_df <- nba_scaled_full |>
    mutate(target = factor(ifelse(cluster == "5", 1, 0))) |>
    select(-cluster)

get_elasnet_top_features(target_cluster_df)
```

What's interesting about this group's features compared to the list of players relates to how much is assisted and the propencity for 3P field goals. 

ChatGPT generated the following label suggestions:

*   Rim Protectors
*   Paint Enforcers
*   Dynamic Bigs
*   Post Specialists
*   Interior Anchors

"Dynamic Bigs" is the only example I like but we're trying to shy away from physical profiles and stick with style/role. Let's target "Interior Connector".

```{r}
# Save cluster label
cluster_labels[cluster_labels$cluster == "5", 2] <- "Interior Connector"
cluster_labels[cluster_labels$cluster == "5", 3] <- "IC"
```

---

#### Cluster #6

Player names:

```{r}
nba_ids[nba_ids$cluster == "6", ]$profile_name
```

Let's pull the top features explaining this cluster assignment:

```{r}
target_cluster_df <- nba_scaled_full |>
    mutate(target = factor(ifelse(cluster == "6", 1, 0))) |>
    select(-cluster)

get_elasnet_top_features(target_cluster_df)
```

These features are interesting. What sticks out? a) their scoring isn't really assisted and 2) there's some unique approach to defense where they draw a lot of fouls.

ChatGPT generated the following label suggestions:

*   Floor Generals
*   Playmaking Guards
*   Perimeter Orchestrators
*   Dynamic Ball Handlers
*   Backcourt Catalysts

Again, we're trying to shy away from traditional terminology. I like "orchestrator" as it eludes more responsibility than just "facilitator". However, it's often used mostly for traditional guard positions. Let's go with "Perimeter Anchor", instead.

```{r}
# Save cluster label
cluster_labels[cluster_labels$cluster == "6", 2] <- "Perimeter Anchor"
cluster_labels[cluster_labels$cluster == "6", 3] <- "PA"
```

---

#### Cluster #7

Player names:

```{r}
nba_ids[nba_ids$cluster == "7", ]$profile_name
```

Let's pull the top features explaining this cluster assignment:

```{r}
target_cluster_df <- nba_scaled_full |>
    mutate(target = factor(ifelse(cluster == "7", 1, 0))) |>
    select(-cluster)

get_elasnet_top_features(target_cluster_df)
```

What sticks out is not efficient scorers. But there is some creating, getting to the free-throw line stuff that's interesting.

ChatGPT generated the following label suggestions:

*   Two-Way Wings
*   Defensive Specialists
*   Versatile Role Players
*   Perimeter Stoppers
*   Glue Guys

There are certainly some good defenders in this list but that's not the primary thing here. "Two-Way" could be good. "Glue" and "connector" are intriguing words. I think the point is they do a bit of everything, but specialize in non-scoring events. Let's go with "Versatile Connector".

```{r}
# Save cluster label
cluster_labels[cluster_labels$cluster == "7", 2] <- "Versatile Connector"
cluster_labels[cluster_labels$cluster == "7", 3] <- "VC"
```

---

#### Cluster #8

Player names:

```{r}
nba_ids[nba_ids$cluster == "8", ]$profile_name
```

Let's pull the top features explaining this cluster assignment:

```{r}
target_cluster_df <- nba_scaled_full |>
    mutate(target = factor(ifelse(cluster == "8", 1, 0))) |>
    select(-cluster)

get_elasnet_top_features(target_cluster_df)
```

What sticks out is the orientation to perimeter activity, clearly.

ChatGPT generated the following label suggestions:

*   Catch-and-Shoot Crew
*   Perimeter Marksmen
*   Wing Snipers
*   Spot-Up Specialists
*   Floor Spacers

I think I like "Perimeter Finisher" best. It fits with some of the other language we've used too so it's cohesive.

```{r}
# Save cluster label
cluster_labels[cluster_labels$cluster == "8", 2] <- "Perimeter Finisher"
cluster_labels[cluster_labels$cluster == "8", 3] <- "PF"
```

---

#### Cluster #9

Player names:

```{r}
nba_ids[nba_ids$cluster == "9", ]$profile_name
```

Let's pull the top features explaining this cluster assignment:
```{r}
target_cluster_df <- nba_scaled_full |>
    mutate(target = factor(ifelse(cluster == "9", 1, 0))) |>
    select(-cluster)

get_elasnet_top_features(target_cluster_df)
```

In the opposite vein to above, this group sticks out for their presence on the interior.

ChatGPT generated the following label suggestions:

*   Rim Protectors
*   Paint Guardians
*   Defensive Anchors
*   Rebounding Specialists
*   Post Defenders

Let's go with "Interior Anchor". This helps describe the role on both ends of the floor. If we were just focused on "offense", we would classify as "Interior Finisher".

```{r}
# Save cluster label
cluster_labels[cluster_labels$cluster == "9", 2] <- "Interior Anchor"
cluster_labels[cluster_labels$cluster == "9", 3] <- "IA"
```

---

#### Cluster #10

Player names:

```{r}
nba_ids[nba_ids$cluster == "10", ]$profile_name
```

Let's pull the top features explaining this cluster assignment:

```{r}
target_cluster_df <- nba_scaled_full |>
    mutate(target = factor(ifelse(cluster == "10", 1, 0))) |>
    select(-cluster)

get_elasnet_top_features(target_cluster_df)
```

What sticks out in this group is 3P shooting with a bunch of rebounding and being in the center of the action. 

ChatGPT generated the following label suggestions:

*   Skilled Bigs
*   Versatile Frontcourt
*   Playmaking Centers
*   Dominant Big Men
*   All-Around Bigs

Let's go with "Interior Engine" for the moment. It describes this idea of engaging the team's "drivetrain" from inside-out.

```{r}
# Save cluster label
cluster_labels[cluster_labels$cluster == "10", 2] <- "Interior Engine"
cluster_labels[cluster_labels$cluster == "10", 3] <- "IE"
```

## New Position Labels

### Summary

Here's our final clusters, with labels and abbreviations. We settled on distinguishing orientation of play and style with "interior", "perimeter", and "versatile" descriptors. Obviously this isn'e exclusive, a "perimeter engine" would certainly score and operate on the interior as well, but it describes their tendencies: "out-in" vs "in-out". 

Next we settled on 4 roles or styles: "connector", "anchor", "finisher", and "engine". Again, these aren't exclusive but indicate where players tend and lean in their overall style and assumed roles.

```{r}
cluster_labels |>
    arrange(label)
```

Let's go through some exercises where we intersect these labels with the original data. Now that these labels have meaning, we can benchmark more easily against domain knowledge.

```{r}
nba_adjusted_full <- nba_adjusted_full |>
    inner_join(cluster_labels) |>
    bind_cols(nba_ids)
```


### Player Distributions

How many players across the NBA fall into these groups? We'd expect "Engines" to have the fewest, the "Versatile" group to be the largest sum overall. Let's see if that matches up with preconceptions.

```{r}
nba_adjusted_full |>
    group_by(label, abbrev) |>
    count() |>
    ungroup() |>
    mutate(perc = n / sum(n))
```

Our theories held pretty well. "Engines" are about the smallest of each of their respective groups. The "Versatile" group is the largest of them all. 

### League Distributions

We have labels for the "current" teams. Let's see how many of each of these belong to each team.

**NOTE: data gathered represents only the top 500 players by minutes over the last 4.5 seasons; therefore, some teams will see fewer than others and some players don't actively belong to a team**

```{r}
nba_adjusted_full |> 
    group_by(profile_team_abbreviation, abbrev) |>
    count() |>
    ungroup() |>
    arrange(abbrev) |>
    pivot_wider(
        names_from = abbrev, 
        values_from = n, 
        values_fill = 0
    ) |>
    gt::gt()
```

It's pretty interesting to see different approaches. 

*   Interior
    -   ORL (Orlando Magic): no Engines or Anchors, but 3 Interior Connectors (Wendell Carter Jr., Goga Bitadze, Jonathan Isaac)
    -   SAS (San Antonio Spurs): no Anchors or Connectors and only 1 Engine (Victor Wembanyama)
*   Perimeter
    -   CLE: 8 players total, 3 of which are Perimeter Finishers (Georges Niang, Max Strus, Sam Merrill)
    -   DEN: only 2 players (Finisher: Justin Holiday, Engine: Jamal Murray) and no Perimeter Anchors
*   Versatile
    -   BOS (Boston Celtics): only 3 players and no Engines or Anchors
    -   SAS (San Antonio Spurs): a total of 13, 6 of which are Versatile Finishers

### Team Distributions

Let's take a team like Boston and see which of our new position labels are getting minutes. Let's workup a quick function for that:

```{r}
peek_team_dist <- function(team) {
    nba_adjusted_full |>
        filter(profile_team_abbreviation == team) |>
        mutate(mp_gm = profile_minutes / profile_games_played) |>
        arrange(desc(mp_gm)) |>
        select(profile_name, label, abbrev, mp_gm) |>
        gt::gt()
}
```

```{r}
peek_team_dist("BOS")
```

Really interesting. Boston is led by their Engines, then Anchors, and then some Connectors.

Let's try another team, say the Portland Trailblazers:

```{r}
peek_team_dist("POR")
```

Here we see some differences, with Connectors featured a little more towards the top wich a lot of Versatile type players as opposed to Perimeter or Interior focused.

### Next Steps

There are **many** avenues to take this analysis. We could analze team performance, understand career earnings through the lens of these more advanced position labels, and much more.

Where we are going to take the analysis is in the direction of NBA prospects. Can we create a model to predict the position a player not yet in the NBA may align with were he to get there?

This next phase requires:

1.  Pre-NBA measures of performance for this group we have positions for
2.  Develop a model with Pre-NBA measures as predictors and new roles as the target
3.  Use the model to predict which prospects assume which roles at the next level