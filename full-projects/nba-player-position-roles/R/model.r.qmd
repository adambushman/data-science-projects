---
title: "Position/role classification of incoming NBA prospects"
description: "Leveraging multiple machine learning methods in R to cluster for player positions/roles and predict the same for incoming NBA prospects."
author: "Adam Bushman"
date: "12/12/2024"
format: 
    html:
        toc: true
        theme: simplex
        smooth-scroll: true
        embed-resources: true
execute:
    warning: false
    error: false
---


# Assignment Workflow

## Organizational Theory

## Data Prep

### Load Libraries & Data Set

```{r}
library("tidyverse")
library("tidymodels")
library("tidyclust")
library("dataPreparation")

library("kernlab") # Weighted kernal k-means
```

```{r}
#| eval: false
setwd("full-projects/nba-player-position-roles/R")
```

Import the data

```{r}
nba_stats <- read.csv("../nba-player-data.csv")
```

```{r}
glimpse(nba_stats)
```

```{r}
# Check for missing or empty values
na_summary <- sapply(nba_stats, function(col) {
    sum(is.na(col) | is.null(col) | col == "", na.rm = TRUE)
})

any(na_summary > 0)
```


### Scale Variables

```{r}
nba_numeric <- nba_stats |> select(
    where(is.numeric) &
    -c(profile_height_in, profile_weight_lbs)
)

nba_ids <- nba_stats |> select(
    where(is.character) | 
    c(profile_games_played, profile_minutes, profile_height_in, profile_weight_lbs)
)
```

```{r}
# Check for non-finite values
nonf_summary <- sapply(nba_numeric, function(col) {
    sum(!is.finite(col), na.rm = TRUE)
})

any(nonf_summary > 0)
```

Create volume adjusted measures based on minutes (i.e. points per "36 minutes", an industry standard).

```{r}
nba_adjusted <- nba_numeric |>
    mutate(across(
        where(is.integer) & -c(profile_games_played, profile_minutes), 
        ~ . * 36.0 / profile_minutes
    )) |> 
    select(-c(profile_games_played, profile_minutes))
```

We also remove the total volume measures as we want to prevent clusters that are similar just based on how much they play.

Scale the numeric variables:

```{r}
nba_scaled <- scale(nba_adjusted)
```

### Principal Component Analysis

Using the scaled variables, let's perform PCA. We'll try to cluster with and without PCA. We'll have both data set versions at our disposal for clustering.

```{r}
library("FactoMineR")
```

```{r}
nba_pca <- princomp(nba_scaled)
```

```{r}
summary(nba_pca)
```

We have 195 numeric, source variables so 199 principal components. The first 15 components explain 75% of variance, the first 40 explain 90% of the variance and the first 57 principal components explain 95%. That means just over 1/4 of our original number of features explain nearly all of the total variance. 

PCA did a good job at 1) reducing dimensionality and 2) eliminating any colinearity of features. 

Let's save our results:

```{r}
nba_pca_data <- as.data.frame(nba_pca$scores)
```

Let's visualize some of these principal components:

```{r}
ggplot(
    nba_pca_data,
    aes(Comp.1, Comp.2)
) +
    geom_point()
```


## Clustering

Let's try to cluster these observations.

Historically, basketball has used 5 positions. In modern times, this has been reduced to approximately 3. Let's use 3 as our minimum and 12 as our maximum. Let's try a few different clustering techniques.

```{r}
clustering_grid <- data.frame(
    clusters = 3:20
)
```

Against each of these, we can run different clustering algorithms and produce measures for the "within sum of squares". This will help us determine the proper number of clusters derived from the data.


### Partition Clustering

Let's setup a function to run a kmeans cluster for every number of cluster in the above grid and generate the respective performance metric:

```{r}
cluster_kmeans <- function(k, data) {
    fit <- kmeans(data, k)
    vals <- glance(fit)
    return(vals$tot.withinss)
}
```   


### Hierarchical Clustering

Let's do the same thing but for an hclust algorithm:

```{r}
cluster_hclust <- function(k, data) {
    # Run the algorithm
    model <- hier_clust(num_clusters = k, linkage_method = "complete")
    fit <- model |> fit(~., data = as.data.frame(data))

    wss <- fit |>
        sse_within() |>
        select(wss) |>
        unlist() |>
        sum()
    return(wss)
}
```

Let's now generate our clusters!

### Cluster Results

Let's map over the number of clusters and execute the respective algorithm.

```{r}
clustering_grid_01 <-
    clustering_grid |>
    mutate(
        kmeans = map(clusters, ~ cluster_kmeans(.x, nba_scaled)),
        hclust = map(clusters, ~ cluster_hclust(.x, nba_scaled))
    )
```

We can now plot these and find the "elbow", or the point of diminishing returns from an increasing the number of clusters.

```{r}
clustering_grid_01 |>
    pivot_longer(cols = -clusters) |>
    unnest(value) |>
    ggplot(aes(factor(clusters), as.numeric(value))) +
    geom_line(aes(color = name), group = 1) +
    facet_wrap(~name, ncol = 1, scales = "free")
```

`hclust` gives the impression that around 10 is the right number of clusters, though the elbow is difficult to identify. `kmeans` suggests 9 or 10.

Let's see if we get different results using just the first 53 principal components. 

```{r}
clustering_grid_02 <-
    clustering_grid |>
    mutate(
        kmeans = map(clusters, ~ cluster_kmeans(.x, nba_pca_data[, 1:57])),
        hclust = map(clusters, ~ cluster_hclust(.x, nba_pca_data[, 1:57]))
    )
```

```{r}
clustering_grid_02 |>
    pivot_longer(cols = -clusters) |>
    unnest(value) |>
    ggplot(aes(factor(clusters), as.numeric(value))) +
    geom_line(aes(color = name), group = 1) +
    facet_wrap(~name, ncol = 1, scales = "free")
```

The same algorithms with the first 57 principal components indicate somewhere around 9 to 10. Let's proceed with the PCA results and assume clusters of `10`. I also think the smoothing of `kmeans` is a little nicer so let's default to that algorithm.

```{r}
set.seed(2015)
fit <- kmeans(nba_pca_data[, 1:57], 10)

nba_ids$cluster <- fit$cluster

nba_ids |> count(cluster) |> mutate(prop = n / sum(n))
```

The initial results seem fairly reasonable. Understandably, some clusters (or as we would interpret, "positions"/"roles"/"styles") have more players than others given the nature of the game.

Let's evaluate some specific players and get a sense for the results.

### Cluster Evaluation

The first example deals with 4 players typically thought of as "centers". Their physical profiles are somewhat similar but there are significant differences in style and role. We should probably see three different cluster assignments.

```{r}
nba_ids |> filter(
    profile_name %in% c(
        "Victor Wembanyama",
        "Nikola Jokic",
        "Clint Capela",
        "Rudy Gobert"
    )
)
```

We see Capela and Gobert with the same cluster assignment, making sense, but Jokic and Wembanyama are also assigned to the same. Given their offensive game, this could make sense, as most of their differentiators are on the defensive end.

Let's try another. These three all have similar physical profiles, roles, and play styles. Let's see how they are clustered.

```{r}
nba_ids |> filter(
    profile_name %in% c(
        "Jimmy Butler",
        "Jayson Tatum",
        "Jaylen Brown"
    )
)
```

We see they all fall into the same cluster! This gives some assurance that the clustering is capturing some of the inherent patterns.

What about all players who've historically been labeled "point guards". Each of these play so differently we should see completely different cluster assignments.

```{r}
nba_ids |> filter(
    profile_name %in% c(
        "Collin Sexton",
        "Bruce Brown",
        "Stephen Curry",
        "Jose Alvarado"
    )
)
```

All different except for Curry and Sexton. We'll have to dig into the cluster more closely to learn about this. So far its tracking pretty close to what a contextual lens might suggest.

Let's look at at some of the most dissimilar players from a physical profile that have the same cluster.

```{r}
getMinMax <- function(data, cluster = 1) {
    data_f <- data[data$cluster == cluster, ]
    data_f$val <- (scale(data_f$profile_height_in) + scale(data_f$profile_weight_lbs)) / 2
    data_f <- data_f |> arrange(desc(val))

    return(c(
        data_f$profile_name[nrow(data_f)],
        data_f$profile_name[1]
    ))
}
```

```{r}
for (c in sort(unique(nba_ids$cluster))) {
    players <- getMinMax(nba_ids, c)
    print(paste(
        c, "- Min:", players[1],
        "| Max:", players[2]
    ))
}
```

Generally speaking, these make a lot of sense. The next step would be to analyze each cluster and come up with unique labels for them that describe the new position/role/style.


### Cluster Naming

We're going to let AI suggest some initial names. We'll then comb through the data surrounding the clusters and make our own minds up.

We'll use the following prompt (along with the list of names) and 5 suggestions from OpenAI's ChatGPT 4o model:

>   Below are a list of recent NBA player names. Assume these players belong in a collective group based on their play style and role. Generate 5 unique suggestions for a group label that is short and sweet but descriptive of the group. Restrict evaluation to style and role; avoid analysis rooted in reputation, playing time, etc.

#### Cluster #1

Player names:

```{r}
nba_ids[nba_ids$cluster == 1,]$profile_name
```

Generated label suggestions:

*   Playmaking Hustlers
*   Versatile Initiators
*   Dynamic Facilitators
*   Crafty Drivers
*   Hybrid Creators

---

#### Cluster #2

Player names:

```{r}
nba_ids[nba_ids$cluster == 2,]$profile_name
```

Generated label suggestions:

*   Versatile Wings
*   Dynamic Bigs
*   Stretch Forwards
*   Two-Way Frontcourt
*   Hybrid Playmakers

---

#### Cluster #3

Player names:

```{r}
nba_ids[nba_ids$cluster == 3,]$profile_name
```

Generated label suggestions:

*   Scoring Wings
*   Perimeter Playmakers
*   Versatile Shooters
*   Dynamic Swingmen
*   Offensive Engines

---

#### Cluster #4

Player names:

```{r}
nba_ids[nba_ids$cluster == 4,]$profile_name
```

Generated label suggestions:

*   Elite Creators
*   Dynamic Scorers
*   Playmaking Stars
*   Offensive Leaders
*   All-Around Playmakers

---

#### Cluster #5

Player names:

```{r}
nba_ids[nba_ids$cluster == 5,]$profile_name
```

Generated label suggestions:

*   Rim Protectors
*   Paint Enforcers
*   Dynamic Bigs
*   Post Specialists
*   Interior Anchors

---

#### Cluster #6

Player names:

```{r}
nba_ids[nba_ids$cluster == 6,]$profile_name
```

Generated label suggestions:

*   Floor Generals
*   Playmaking Guards
*   Perimeter Orchestrators
*   Dynamic Ball Handlers
*   Backcourt Catalysts

---

#### Cluster #7

Player names:

```{r}
nba_ids[nba_ids$cluster == 7,]$profile_name
```

Generated label suggestions:

*   Two-Way Wings
*   Defensive Specialists
*   Versatile Role Players
*   Perimeter Stoppers
*   Glue Guys

---

#### Cluster #8

Player names:

```{r}
nba_ids[nba_ids$cluster == 8,]$profile_name
```

Generated label suggestions:

*   Catch-and-Shoot Crew
*   Perimeter Marksmen
*   Wing Snipers
*   Spot-Up Specialists
*   Floor Spacers

Offense: *Perimeter Finishers*

---

#### Cluster #9

Player names:

```{r}
nba_ids[nba_ids$cluster == 9,]$profile_name
```

Generated label suggestions:

*   Rim Protectors
*   Paint Guardians
*   Defensive Anchors
*   Rebounding Specialists
*   Post Defenders

Offense: *Interior Finishers*

---

#### Cluster #10

Player names:

```{r}
nba_ids[nba_ids$cluster == 10,]$profile_name
```

Generated label suggestions:

*   Skilled Bigs
*   Versatile Frontcourt
*   Playmaking Centers
*   Dominant Big Men
*   All-Around Bigs